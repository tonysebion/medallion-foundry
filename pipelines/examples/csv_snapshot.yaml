# yaml-language-server: $schema=../schema/pipeline.schema.json
#
# TEMPLATE: CSV File Full Snapshot
# ================================
# Use this for CSV files that are full snapshots:
# - Daily export files from legacy systems
# - Files that contain all records each time
#
# To run:
#   python -m pipelines ./pipelines/examples/csv_snapshot.yaml --date 2025-01-15

# Optional metadata
name: csv_snapshot_template
description: Template for loading full snapshot CSV files

# Bronze layer - raw data extraction
bronze:
  system: your_system       # e.g., "legacy_erp", "salesforce"
  entity: your_entity       # e.g., "customers", "orders"
  source_type: file_csv
  source_path: "./data/{entity}_{run_date}.csv"
  # load_pattern defaults to full_snapshot
  # target_path auto-generates: ./bronze/system=your_system/entity=your_entity/dt={run_date}/
  # For S3: target_path: "s3://bucket/bronze/your_system/your_entity/dt={run_date}/"

# Silver layer - data curation
silver:
  domain: your_domain           # Business domain (e.g., sales, finance, hr)
  subject: your_subject         # Subject area (e.g., orders, customers)
  unique_columns: [id]            # What makes a record unique?
  last_updated_column: updated_at  # When was the record last changed?
  # target_path auto-generates: ./silver/domain=your_domain/subject=your_subject/dt={run_date}/
  # For S3: target_path: "s3://bucket/silver/domain=your_domain/subject=your_subject/dt={run_date}/"
  # entity_kind defaults to state
  # history_mode defaults to current_only (SCD Type 1)
