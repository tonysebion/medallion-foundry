"""Generate realistic Bronze sample datasets for testing load patterns."""

from __future__ import annotations

import csv
import json
from datetime import datetime, timedelta, timezone
from pathlib import Path
from random import Random
from typing import Iterable, List, Dict

BASE_DIR = Path(__file__).resolve().parents[1] / "docs" / "examples" / "data" / "bronze_samples"


FULL_DATES = ["2025-11-13", "2025-11-14"]
CDC_DATES = ["2025-11-13", "2025-11-14"]
CURRENT_HISTORY_DATES = ["2025-11-13", "2025-11-14"]


def _write_csv(path: Path, rows: Iterable[Dict[str, object]]) -> None:
    rows = list(rows)
    if not rows:
        return
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", newline="", encoding="utf-8") as handle:
        writer = csv.DictWriter(handle, fieldnames=rows[0].keys())
        writer.writeheader()
        writer.writerows(rows)


def _write_metadata(target_dir: Path, pattern: str, record_count: int, chunk_count: int) -> None:
    metadata = {
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "record_count": record_count,
        "chunk_count": chunk_count,
        "load_pattern": pattern,
        "notes": "Autogenerated sample data for Bronze/Silver integration tests.",
    }
    with (target_dir / "_metadata.json").open("w", encoding="utf-8") as handle:
        json.dump(metadata, handle, indent=2)


def generate_full_snapshot(seed: int = 42, row_count: int = 500) -> None:
    for day_offset, date_str in enumerate(FULL_DATES):
        rng = Random(seed + day_offset)
        base_dir = BASE_DIR / "full" / "system=retail_demo" / "table=orders" / "pattern=full" / f"dt={date_str}"
        rows: List[Dict[str, object]] = []
        start = datetime.fromisoformat(f"{date_str}T00:00:00")
        total_rows = row_count + day_offset * 50
        for order_id in range(1, total_rows + 1):
            order_time = start + timedelta(hours=order_id)
            rows.append(
                {
                    "order_id": f"ORD-{order_id + day_offset * 1000:05d}",
                    "customer_id": f"CUST-{rng.randint(1000, 9999)}",
                    "status": rng.choice(["new", "processing", "shipped", "delivered", "returned"]),
                    "order_total": round(rng.uniform(25.0, 500.0), 2),
                    "updated_at": order_time.isoformat() + "Z",
                    "run_date": date_str,
                }
            )

        chunk_path = base_dir / "full-part-0001.csv"
        _write_csv(chunk_path, rows)
        _write_metadata(base_dir, "full", len(rows), 1)


def generate_cdc(seed: int = 99, row_count: int = 400) -> None:
    change_types = ["insert", "update", "delete"]
    for day_offset, date_str in enumerate(CDC_DATES):
        rng = Random(seed + day_offset)
        base_dir = BASE_DIR / "cdc" / "system=retail_demo" / "table=orders" / "pattern=cdc" / f"dt={date_str}"
        rows: List[Dict[str, object]] = []
        start = datetime.fromisoformat(f"{date_str}T08:00:00")

        total_rows = row_count + day_offset * 60
        for idx in range(1, total_rows + 1):
            change_time = start + timedelta(minutes=idx * 3)
            rows.append(
                {
                    "order_id": f"ORD-{rng.randint(1, 800):05d}",
                    "customer_id": f"CUST-{rng.randint(1000, 9999)}",
                    "change_type": rng.choice(change_types),
                    "changed_at": change_time.isoformat() + "Z",
                    "status": rng.choice(["processing", "shipped", "cancelled"]),
                    "order_total": round(rng.uniform(10.0, 800.0), 2),
                    "run_date": date_str,
                }
            )

        chunk_path = base_dir / "cdc-part-0001.csv"
        _write_csv(chunk_path, rows)
        _write_metadata(base_dir, "cdc", len(rows), 1)


def generate_current_history(seed: int = 7, current_rows: int = 200, history_rows: int = 600) -> None:
    for day_offset, date_str in enumerate(CURRENT_HISTORY_DATES):
        rng = Random(seed + day_offset)
        base_dir = (
            BASE_DIR
            / "current_history"
            / "system=retail_demo"
            / "table=orders"
            / "pattern=current_history"
            / f"dt={date_str}"
        )

        def build_history_rows() -> List[Dict[str, object]]:
            rows: List[Dict[str, object]] = []
            base_time = datetime(2024, 1, 1) + timedelta(days=day_offset * 30)
            total_rows = history_rows + day_offset * 80
            for idx in range(1, total_rows + 1):
                start_ts = base_time + timedelta(days=rng.randint(0, 365))
                end_ts = start_ts + timedelta(days=rng.randint(5, 120))
                rows.append(
                    {
                        "order_id": f"ORD-{rng.randint(1, 1200):05d}",
                        "customer_id": f"CUST-{rng.randint(1000, 9999)}",
                        "status": rng.choice(["active", "expired", "suspended"]),
                        "effective_start": start_ts.isoformat() + "Z",
                        "effective_end": end_ts.isoformat() + "Z",
                        "current_flag": 0,
                        "updated_at": (end_ts + timedelta(hours=2)).isoformat() + "Z",
                        "run_date": date_str,
                    }
                )
            return rows

        def build_current_rows() -> List[Dict[str, object]]:
            rows: List[Dict[str, object]] = []
            start_time = datetime.fromisoformat(f"{date_str}T00:00:00")
            total_rows = current_rows + day_offset * 40
            for idx in range(1, total_rows + 1):
                rows.append(
                    {
                        "order_id": f"ORD-{idx + 900 + day_offset * 500:05d}",
                        "customer_id": f"CUST-{rng.randint(2000, 9999)}",
                        "status": rng.choice(["active", "pending", "suspended"]),
                        "effective_start": "",
                        "effective_end": "",
                        "current_flag": 1,
                        "updated_at": (start_time + timedelta(hours=idx)).isoformat() + "Z",
                        "run_date": date_str,
                    }
                )
            return rows

        history_data = build_history_rows()
        current_data = build_current_rows()
        _write_csv(base_dir / "current-history-part-0001.csv", history_data + current_data)
        _write_metadata(base_dir, "current_history", len(history_data) + len(current_data), 1)


def main() -> None:
    generate_full_snapshot()
    generate_cdc()
    generate_current_history()
    print(f"Sample datasets written under {BASE_DIR}")


if __name__ == "__main__":
    main()
